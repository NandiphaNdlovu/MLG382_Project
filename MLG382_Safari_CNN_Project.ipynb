{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1k3kZHo6Gwl"
   },
   "source": [
    "# Safari Challenge\n",
    "\n",
    "In this challenge, you must use what you've learned to train a convolutional neural network model that classifies images of animals you might find on a safari adventure.\n",
    "\n",
    "## Explore the data\n",
    "\n",
    "The training images you must use are in the **/safari/training** folder. Run the cell below to see an example of each image class, and note the shape of the images (which indicates the dimensions of the image and its color channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "VV-V4AK46Gwm",
    "outputId": "b7e9371c-905a-47bb-c89b-58924576cb2c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "# The images are in the safari/training folder\n",
    "data_path = \"safari/training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 classes:\n",
      "['elefante', 'elephant', 'giraffe', 'lion', 'zebra']\n"
     ]
    }
   ],
   "source": [
    "# Get the class names\n",
    "#classes = os.listdir(data_path)\n",
    "classes = [sub_dir for sub_dir in os.listdir(data_path) if not sub_dir.startswith('.')]\n",
    "classes.sort()\n",
    "print(len(classes), 'classes:')\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: 'safari/training/.DS_Store'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_dir \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(data_path): \u001b[38;5;66;03m#starts a loop that iterates over each item (subdirectory) in the list of directories within the data_path directory,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 6\u001b[0m     img_file \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43msub_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, sub_dir, img_file)\n\u001b[1;32m      8\u001b[0m     img \u001b[38;5;241m=\u001b[39m mpimg\u001b[38;5;241m.\u001b[39mimread(img_path) \u001b[38;5;66;03m#The image data is stored in the variable img\u001b[39;00m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: 'safari/training/.DS_Store'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the first image in each folder\n",
    "fig = plt.figure(figsize=(12, 12))#sets the size of the figure to 12x12 inches using the figsize parameter\n",
    "i = 0\n",
    "for sub_dir in os.listdir(data_path): #starts a loop that iterates over each item (subdirectory) in the list of directories within the data_path directory,\n",
    "    i+=1\n",
    "    img_file = os.listdir(os.path.join(data_path,sub_dir))[0]\n",
    "    img_path = os.path.join(data_path, sub_dir, img_file)\n",
    "    img = mpimg.imread(img_path) #The image data is stored in the variable img\n",
    "    img_shape = np.array(img).shape \n",
    "    a=fig.add_subplot(1, len(classes),i)\n",
    "    a.axis('off')\n",
    "    imgplot = plt.imshow(img)\n",
    "    a.set_title(img_file + ' : ' + str(sub_dir))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(12, 12))#sets the size of the figure to 12x12 inches using the figsize parameter\n",
    "\n",
    "# with specific name in the class\n",
    "target_class = 'zebra'\n",
    "i = 0\n",
    "for sub_dir in os.listdir(data_path):\n",
    "    if sub_dir == target_class:\n",
    "        i += 1\n",
    "        img_file = os.listdir(os.path.join(data_path, sub_dir))[0]\n",
    "        img_path = os.path.join(data_path, sub_dir, img_file)\n",
    "        img = mpimg.imread(img_path)\n",
    "        img_shape = img.shape\n",
    "        a = fig.add_subplot(1, len(classes), i)\n",
    "        a.axis('off')\n",
    "        imgplot = plt.imshow(img)\n",
    "        a.set_title(img_file + ' : ' + str(img_shape))\n",
    "        print(sub_dir)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kxIicPI6Gwo"
   },
   "source": [
    "Now that you've seen the images, use your preferred framework (PyTorch or TensorFlow) to train a CNN classifier for them. Your goal is to train a classifier with a validation accuracy of 95% or higher.\n",
    "\n",
    "Add cells as needed to create your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xd4bdg8a6Gwo"
   },
   "source": [
    "### Install and import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Define a CNN classifier network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAXX68cd6Gwo"
   },
   "source": [
    "### Define CNN\n",
    "Below are some suggested steps to follow or you can use your own steps to define your CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (200,200)\n",
    "batch_size = 30\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255,validation_split=0.3)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # set as training data\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # set as validation data\n",
    "\n",
    "\n",
    "# Define the model as a sequence of layers\n",
    "model = Sequential()\n",
    "\n",
    "# The input layer accepts an image and applies a convolution that uses 32 6x6 filters and a rectified linear unit activation function\n",
    "model.add(Conv2D(32, (6, 6), input_shape=train_generator.image_shape, activation='relu'))\n",
    "\n",
    "# Next we'll add a max pooling layer with a 2x2 patch\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# We can add as many layers as we think necessary - here we'll add another convolution and max pooling layer\n",
    "model.add(Conv2D(32, (6, 6), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# And another set\n",
    "model.add(Conv2D(32, (6, 6), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# A dropout layer randomly drops some nodes to reduce inter-dependencies (which can cause over-fitting)\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Now we'll flatten the feature maps and generate an output layer with a predicted probability for each class\n",
    "model.add(Flatten())\n",
    "model.add(Dense(train_generator.num_classes, activation='softmax'))\n",
    "\n",
    "# With the layers defined, we can now compile the model for categorical (multi-class) classification\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8FRqKAE6Gwp"
   },
   "source": [
    "### Train the model\n",
    "Train a CNN model with 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldE3B1NE6Gwp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your Code to train a CNN model...\n",
    "num_epochs = 5\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMTj1zC56Gwp"
   },
   "source": [
    "### View loss history\n",
    "- To check for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BS-8DiA06Gwp"
   },
   "outputs": [],
   "source": [
    "epoch_nums = range(1, num_epochs+1)\n",
    "training_loss = history.history[\"loss\"]\n",
    "validation_loss = history.history[\"val_loss\"]\n",
    "plt.plot(epoch_nums, training_loss, color='Pink')\n",
    "plt.plot(epoch_nums, validation_loss, color='Purple')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_BasbY76Gwp"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames = list(train_generator.class_indices.keys())\n",
    "\n",
    "print(\"Generating predictions from validation data...\")\n",
    "# Get the image and label arrays for the first batch of validation data\n",
    "x_test = validation_generator[0][0]\n",
    "y_test = validation_generator[0][1]\n",
    "\n",
    "# Use the model to predict the class\n",
    "class_probabilities = model.predict(x_test)\n",
    "\n",
    "# The model returns a probability value for each class\n",
    "# The one with the highest probability is the predicted class\n",
    "predictions = np.argmax(class_probabilities, axis=1)\n",
    "\n",
    "# The actual labels are hot encoded (e.g. [0 1 0], so get the one with the value 1\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.RdPu)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classnames))\n",
    "plt.xticks(tick_marks, classnames, rotation=85)\n",
    "plt.yticks(tick_marks, classnames)\n",
    "plt.xlabel(\"Predicted Shape\")\n",
    "plt.ylabel(\"Actual Shape\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pB9fCilG6Gwq"
   },
   "source": [
    "### Save your model\n",
    "\n",
    "Add code below to save your model's trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "modelFileName = 'safari_adventure_animal_classifier.h5'\n",
    "model.save(modelFileName)\n",
    "del model  # deletes the existing model variable\n",
    "print('The model has been saved as', modelFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s60xJqVm6Gwq"
   },
   "source": [
    "### Use the trained model\n",
    "\n",
    "Now that we've trained your model, modify the following code as necessary to use it to predict the classes of the provided test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gl9JDAl86Gwq",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Function to predict the class of an image\n",
    "def predict_image(classifier, image):\n",
    "    from tensorflow import convert_to_tensor\n",
    "    # The model expects a batch of images as input, so we'll create an array of 1 image\n",
    "    imgfeatures = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "\n",
    "    # We need to format the input to match the training data\n",
    "    # The generator loaded the values as floating point numbers\n",
    "    # and normalized the pixel values, so...\n",
    "    imgfeatures = imgfeatures.astype('float32')\n",
    "    imgfeatures /= 255\n",
    "    \n",
    "    # Use the model to predict the image class\n",
    "    class_probabilities = classifier.predict(imgfeatures)\n",
    "    \n",
    "    # Find the class predictions with the highest predicted probability\n",
    "    index = int(np.argmax(class_probabilities, axis=1)[0])\n",
    "    return index\n",
    "\n",
    "\n",
    "# Load your model\n",
    "model = models.load_model(modelFileName) # loads the saved model\n",
    "\n",
    "# The images are in the data/shapes folder\n",
    "test_data_path = 'safari/test'\n",
    "\n",
    "# Show the test images with predictions\n",
    "fig = plt.figure(figsize=(8, 12))\n",
    "i = 0\n",
    "for img_file in os.listdir(test_data_path):\n",
    "    i+=1\n",
    "    img_path = os.path.join(test_data_path, img_file)\n",
    "    img = mpimg.imread(img_path)\n",
    "    # Get the image class prediction\n",
    "    index = predict_image(model, np.array(img))\n",
    "    a=fig.add_subplot(1, len(classes),i)\n",
    "    a.axis('off')\n",
    "    imgplot = plt.imshow(img)\n",
    "    a.set_title(classes[index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
